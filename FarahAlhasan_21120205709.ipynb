{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb921b71",
   "metadata": {},
   "source": [
    "# 3D Stereo Depth Reconstruction Using Numerical Optimization\n",
    "\n",
    "**MAT353 Numerical Analysis Course Project**\n",
    "\n",
    "**Student:** Farah Alhasan\n",
    "\n",
    "**Student ID:** 21120205709\n",
    "\n",
    "**GitHub:** https://github.com/FarahBebs/3D-STEREO-DEPTH-RECONSTRUCTION\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements stereo depth reconstruction using:\n",
    "- **Block Matching**: Traditional SSD-based disparity computation\n",
    "- **Levenberg-Marquardt Optimization**: Numerical optimization for disparity refinement\n",
    "- **Depth Reconstruction**: Converting disparity to 3D depth\n",
    "- **Point Cloud Generation**: 3D reconstruction from depth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba541efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install numpy scipy opencv-python matplotlib -q\n",
    "\n",
    "print(\"\u2713 All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc2430",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "import cv2\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set matplotlib parameters for better visualization\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"\u2713 Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af7e5fc",
   "metadata": {},
   "source": [
    "## 3. Synthetic Stereo Data Generation\n",
    "\n",
    "Generate synthetic stereo pairs with known ground truth disparity for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_stereo_pair(width=640, height=480, num_objects=20):\n",
    "    \"\"\"\n",
    "    Generate synthetic stereo pair with ground truth disparity.\n",
    "    \n",
    "    Parameters:\n",
    "    - width, height: Image dimensions\n",
    "    - num_objects: Number of objects in scene\n",
    "    \n",
    "    Returns:\n",
    "    - left_image, right_image: Stereo pair\n",
    "    - gt_disparity: Ground truth disparity map\n",
    "    - camera_params: Camera parameters\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create depth map with multiple planes\n",
    "    depth_map = np.ones((height, width)) * 100.0\n",
    "    \n",
    "    # Add random rectangles at different depths\n",
    "    for i in range(num_objects):\n",
    "        x = np.random.randint(50, width - 100)\n",
    "        y = np.random.randint(50, height - 100)\n",
    "        w = np.random.randint(40, 120)\n",
    "        h = np.random.randint(40, 120)\n",
    "        depth = np.random.uniform(20, 80)\n",
    "        \n",
    "        depth_map[y:y+h, x:x+w] = depth\n",
    "    \n",
    "    # Apply Gaussian smoothing for realistic depth transitions\n",
    "    depth_map = cv2.GaussianBlur(depth_map, (15, 15), 5)\n",
    "    \n",
    "    # Camera parameters\n",
    "    focal_length = 500.0  # pixels\n",
    "    baseline = 10.0  # cm\n",
    "    \n",
    "    # Compute ground truth disparity: d = (f * B) / Z\n",
    "    gt_disparity = (focal_length * baseline) / depth_map\n",
    "    gt_disparity = np.clip(gt_disparity, 0, 64)\n",
    "    \n",
    "    # Create textured left image\n",
    "    left_image = np.random.randint(0, 256, (height, width), dtype=np.uint8)\n",
    "    left_image = cv2.GaussianBlur(left_image, (5, 5), 1.5)\n",
    "    \n",
    "    # Add some structured patterns\n",
    "    for i in range(0, height, 40):\n",
    "        cv2.line(left_image, (0, i), (width, i), int(np.random.randint(100, 200)), 2)\n",
    "    for j in range(0, width, 40):\n",
    "        cv2.line(left_image, (j, 0), (j, height), int(np.random.randint(100, 200)), 2)\n",
    "    \n",
    "    # Generate right image by shifting according to disparity\n",
    "    right_image = np.zeros_like(left_image)\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            d = int(gt_disparity[y, x])\n",
    "            if x - d >= 0:\n",
    "                right_image[y, x - d] = left_image[y, x]\n",
    "    \n",
    "    # Fill occlusions in right image\n",
    "    mask = right_image == 0\n",
    "    right_image[mask] = np.random.randint(0, 256, np.sum(mask), dtype=np.uint8)\n",
    "    \n",
    "    camera_params = {\n",
    "        'focal_length': focal_length,\n",
    "        'baseline': baseline,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    }\n",
    "    \n",
    "    return left_image, right_image, gt_disparity, camera_params\n",
    "\n",
    "# Generate synthetic stereo pair\n",
    "left_img, right_img, gt_disp, cam_params = generate_synthetic_stereo_pair()\n",
    "\n",
    "print(\"\u2713 Synthetic stereo pair generated!\")\n",
    "print(f\"Image dimensions: {left_img.shape}\")\n",
    "print(f\"Disparity range: [{gt_disp.min():.2f}, {gt_disp.max():.2f}] pixels\")\n",
    "print(f\"Focal length: {cam_params['focal_length']} pixels\")\n",
    "print(f\"Baseline: {cam_params['baseline']} cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f04f8b",
   "metadata": {},
   "source": [
    "### Visualize Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(left_img, cmap='gray')\n",
    "axes[0].set_title('Left Image', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(right_img, cmap='gray')\n",
    "axes[1].set_title('Right Image', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "im = axes[2].imshow(gt_disp, cmap='jet')\n",
    "axes[2].set_title('Ground Truth Disparity', fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04, label='Disparity (pixels)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Ground truth disparity statistics:\")\n",
    "print(f\"  Mean: {gt_disp.mean():.2f} pixels\")\n",
    "print(f\"  Std: {gt_disp.std():.2f} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a42a3",
   "metadata": {},
   "source": [
    "## 4. Block Matching Algorithm\n",
    "\n",
    "Implement traditional block matching using Sum of Squared Differences (SSD) criterion.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "For each pixel $(x, y)$ in the left image, find disparity $d$ that minimizes:\n",
    "\n",
    "$$E(d) = \\sum_{i,j \\in W} \\left( I_{left}(x+i, y+j) - I_{right}(x-d+i, y+j) \\right)^2$$\n",
    "\n",
    "where $W$ is the matching window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b745c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_disparity_block_matching(left_image, right_image, block_size=15, max_disparity=64):\n",
    "    \"\"\"\n",
    "    Compute disparity map using block matching with Sum of Squared Differences (SSD).\n",
    "    \n",
    "    Parameters:\n",
    "    - left_image: Rectified left image (grayscale)\n",
    "    - right_image: Rectified right image (grayscale)\n",
    "    - block_size: Size of the matching block (odd number)\n",
    "    - max_disparity: Maximum disparity to search\n",
    "    \n",
    "    Returns:\n",
    "    - disparity_map: Computed disparity map (pixels)\n",
    "    \"\"\"\n",
    "    height, width = left_image.shape\n",
    "    disparity_map = np.zeros((height, width), dtype=np.float32)\n",
    "    half_block = block_size // 2\n",
    "    \n",
    "    print(f\"Computing disparity using block matching...\")\n",
    "    print(f\"  Block size: {block_size}x{block_size}\")\n",
    "    print(f\"  Max disparity: {max_disparity}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for y in range(half_block, height - half_block):\n",
    "        # Progress indicator\n",
    "        if y % 50 == 0:\n",
    "            progress = (y - half_block) / (height - 2 * half_block) * 100\n",
    "            print(f\"  Progress: {progress:.1f}%\", end='\\r')\n",
    "        \n",
    "        for x in range(half_block, width - half_block):\n",
    "            # Extract left block\n",
    "            left_block = left_image[y - half_block:y + half_block + 1,\n",
    "                                   x - half_block:x + half_block + 1]\n",
    "            \n",
    "            # Search for best match in right image\n",
    "            min_ssd = float('inf')\n",
    "            best_disparity = 0\n",
    "            \n",
    "            for d in range(max_disparity + 1):\n",
    "                if x - d - half_block < 0:\n",
    "                    continue\n",
    "                \n",
    "                # Extract right block\n",
    "                right_block = right_image[y - half_block:y + half_block + 1,\n",
    "                                         x - d - half_block:x - d + half_block + 1]\n",
    "                \n",
    "                # Compute SSD\n",
    "                ssd = np.sum((left_block.astype(float) - right_block.astype(float)) ** 2)\n",
    "                \n",
    "                if ssd < min_ssd:\n",
    "                    min_ssd = ssd\n",
    "                    best_disparity = d\n",
    "            \n",
    "            disparity_map[y, x] = best_disparity\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\n  Completed in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return disparity_map\n",
    "\n",
    "# Compute disparity using block matching\n",
    "BLOCK_SIZE = 15\n",
    "MAX_DISPARITY = 64\n",
    "\n",
    "disparity_bm = compute_disparity_block_matching(left_img, right_img, BLOCK_SIZE, MAX_DISPARITY)\n",
    "\n",
    "print(f\"\\n\u2713 Block matching disparity computed!\")\n",
    "print(f\"Disparity statistics:\")\n",
    "print(f\"  Mean: {disparity_bm.mean():.2f} pixels\")\n",
    "print(f\"  Std: {disparity_bm.std():.2f} pixels\")\n",
    "print(f\"  Range: [{disparity_bm.min():.2f}, {disparity_bm.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd05cc5",
   "metadata": {},
   "source": [
    "### Visualize Block Matching Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4295b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "im1 = axes[0].imshow(gt_disp, cmap='jet')\n",
    "axes[0].set_title('Ground Truth Disparity', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04, label='Disparity (pixels)')\n",
    "\n",
    "im2 = axes[1].imshow(disparity_bm, cmap='jet')\n",
    "axes[1].set_title('Block Matching Disparity', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04, label='Disparity (pixels)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute error metrics\n",
    "error_bm = np.abs(disparity_bm - gt_disp)\n",
    "mae_bm = error_bm.mean()\n",
    "rmse_bm = np.sqrt((error_bm ** 2).mean())\n",
    "\n",
    "print(f\"\\nBlock Matching Error Metrics:\")\n",
    "print(f\"  Mean Absolute Error (MAE): {mae_bm:.3f} pixels\")\n",
    "print(f\"  Root Mean Square Error (RMSE): {rmse_bm:.3f} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2d83e",
   "metadata": {},
   "source": [
    "## 5. Levenberg-Marquardt Optimization\n",
    "\n",
    "Refine disparity estimates using numerical optimization.\n",
    "\n",
    "### Levenberg-Marquardt Algorithm\n",
    "\n",
    "The LM algorithm solves nonlinear least squares problems:\n",
    "\n",
    "$$\\min_d \\sum_i r_i(d)^2$$\n",
    "\n",
    "where $r_i(d) = I_{left}(i) - I_{right}(i-d)$ are residuals.\n",
    "\n",
    "The update rule is:\n",
    "\n",
    "$$d_{k+1} = d_k - (J^T J + \\lambda I)^{-1} J^T r(d_k)$$\n",
    "\n",
    "where $J$ is the Jacobian and $\\lambda$ is the damping parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a43306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_residuals(disparity, left_block, right_image, x, y, half_block):\n",
    "    \"\"\"\n",
    "    Compute SSD residuals for Levenberg-Marquardt optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    - disparity: Array with single disparity value\n",
    "    - left_block: Left image block (flattened)\n",
    "    - right_image: Right image\n",
    "    - x, y: Block center coordinates\n",
    "    - half_block: Half block size\n",
    "    \n",
    "    Returns:\n",
    "    - residuals: Difference between left and right blocks\n",
    "    \"\"\"\n",
    "    d = int(np.clip(disparity[0], 0, 64))\n",
    "    \n",
    "    if x - d - half_block < 0 or x - d + half_block + 1 > right_image.shape[1]:\n",
    "        return np.full_like(left_block, 1000.0)\n",
    "    \n",
    "    right_block = right_image[y - half_block:y + half_block + 1,\n",
    "                              x - d - half_block:x - d + half_block + 1]\n",
    "    \n",
    "    residuals = left_block - right_block.flatten().astype(float)\n",
    "    return residuals\n",
    "\n",
    "\n",
    "def optimize_disparity_levenberg_marquardt(left_image, right_image, initial_disparity,\n",
    "                                           block_size=15, num_pixels=500):\n",
    "    \"\"\"\n",
    "    Refine disparity using Levenberg-Marquardt optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    - left_image: Left image (grayscale)\n",
    "    - right_image: Right image (grayscale)\n",
    "    - initial_disparity: Initial disparity estimate\n",
    "    - block_size: Matching block size\n",
    "    - num_pixels: Number of pixels to optimize\n",
    "    \n",
    "    Returns:\n",
    "    - optimized_disparity: Refined disparity map\n",
    "    - error_history: Optimization error history\n",
    "    - convergence_info: Information about convergence\n",
    "    \"\"\"\n",
    "    height, width = left_image.shape\n",
    "    optimized_disparity = initial_disparity.copy()\n",
    "    half_block = block_size // 2\n",
    "    \n",
    "    print(f\"\\nOptimizing disparity using Levenberg-Marquardt...\")\n",
    "    print(f\"  Number of pixels to optimize: {num_pixels}\")\n",
    "    \n",
    "    # Select random pixels to optimize\n",
    "    np.random.seed(42)\n",
    "    pixels_to_optimize = []\n",
    "    for _ in range(num_pixels):\n",
    "        y = np.random.randint(half_block, height - half_block)\n",
    "        x = np.random.randint(half_block + 64, width - half_block)\n",
    "        pixels_to_optimize.append((y, x))\n",
    "    \n",
    "    all_errors = []\n",
    "    successful_optimizations = 0\n",
    "    convergence_messages = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, (y, x) in enumerate(pixels_to_optimize):\n",
    "        if idx % 100 == 0:\n",
    "            progress = idx / len(pixels_to_optimize) * 100\n",
    "            print(f\"  Progress: {progress:.1f}%\", end='\\r')\n",
    "        \n",
    "        # Extract left block\n",
    "        left_block = left_image[y - half_block:y + half_block + 1,\n",
    "                               x - half_block:x + half_block + 1].flatten().astype(float)\n",
    "        \n",
    "        # Initial guess from block matching\n",
    "        d0 = initial_disparity[y, x]\n",
    "        \n",
    "        # Optimize using Levenberg-Marquardt\n",
    "        try:\n",
    "            result = least_squares(\n",
    "                ssd_residuals,\n",
    "                [d0],\n",
    "                args=(left_block, right_image, x, y, half_block),\n",
    "                method='lm',\n",
    "                max_nfev=50,\n",
    "                ftol=1e-6,\n",
    "                xtol=1e-6\n",
    "            )\n",
    "            \n",
    "            if result.success:\n",
    "                optimized_disparity[y, x] = np.clip(result.x[0], 0, 64)\n",
    "                successful_optimizations += 1\n",
    "                all_errors.append(result.cost)\n",
    "                convergence_messages.append(result.message)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n  Completed in {elapsed_time:.2f} seconds\")\n",
    "    print(f\"  Successful optimizations: {successful_optimizations}/{num_pixels}\")\n",
    "    print(f\"  Success rate: {successful_optimizations/num_pixels*100:.1f}%\")\n",
    "    \n",
    "    convergence_info = {\n",
    "        'total': num_pixels,\n",
    "        'successful': successful_optimizations,\n",
    "        'time': elapsed_time\n",
    "    }\n",
    "    \n",
    "    return optimized_disparity, all_errors, convergence_info\n",
    "\n",
    "# Optimize disparity\n",
    "NUM_OPTIMIZE_PIXELS = 500\n",
    "\n",
    "disparity_opt, error_history, convergence_info = optimize_disparity_levenberg_marquardt(\n",
    "    left_img, right_img, disparity_bm, BLOCK_SIZE, NUM_OPTIMIZE_PIXELS\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Optimization completed!\")\n",
    "print(f\"Optimized disparity statistics:\")\n",
    "print(f\"  Mean: {disparity_opt.mean():.2f} pixels\")\n",
    "print(f\"  Std: {disparity_opt.std():.2f} pixels\")\n",
    "print(f\"  Range: [{disparity_opt.min():.2f}, {disparity_opt.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f721e",
   "metadata": {},
   "source": [
    "### Optimization Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7afc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization error\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Error distribution\n",
    "if len(error_history) > 0:\n",
    "    axes[0].hist(error_history, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_xlabel('Final Cost (SSD)', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].set_title('Distribution of Optimization Final Costs', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Error progression\n",
    "    axes[1].plot(error_history, 'o-', color='darkred', markersize=3, alpha=0.6)\n",
    "    axes[1].set_xlabel('Optimization Index', fontsize=12)\n",
    "    axes[1].set_ylabel('Final Cost (SSD)', fontsize=12)\n",
    "    axes[1].set_title('Optimization Cost per Pixel', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'No error data', ha='center', va='center')\n",
    "    axes[1].text(0.5, 0.5, 'No error data', ha='center', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if len(error_history) > 0:\n",
    "    print(f\"\\nOptimization Error Statistics:\")\n",
    "    print(f\"  Mean final cost: {np.mean(error_history):.2f}\")\n",
    "    print(f\"  Median final cost: {np.median(error_history):.2f}\")\n",
    "    print(f\"  Std final cost: {np.std(error_history):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243e846",
   "metadata": {},
   "source": [
    "### Compare Disparity Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02678dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "im1 = axes[0].imshow(gt_disp, cmap='jet', vmin=0, vmax=64)\n",
    "axes[0].set_title('Ground Truth Disparity', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04, label='Disparity (pixels)')\n",
    "\n",
    "im2 = axes[1].imshow(disparity_bm, cmap='jet', vmin=0, vmax=64)\n",
    "axes[1].set_title('Block Matching', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04, label='Disparity (pixels)')\n",
    "\n",
    "im3 = axes[2].imshow(disparity_opt, cmap='jet', vmin=0, vmax=64)\n",
    "axes[2].set_title('Levenberg-Marquardt Optimized', fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04, label='Disparity (pixels)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute error metrics for both methods\n",
    "error_opt = np.abs(disparity_opt - gt_disp)\n",
    "mae_opt = error_opt.mean()\n",
    "rmse_opt = np.sqrt((error_opt ** 2).mean())\n",
    "\n",
    "print(f\"\\n{'Method':<30} {'MAE (pixels)':<15} {'RMSE (pixels)':<15}\")\n",
    "print(f\"{'-'*60}\")\n",
    "print(f\"{'Block Matching':<30} {mae_bm:<15.3f} {rmse_bm:<15.3f}\")\n",
    "print(f\"{'Levenberg-Marquardt':<30} {mae_opt:<15.3f} {rmse_opt:<15.3f}\")\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  MAE reduction: {(mae_bm - mae_opt)/mae_bm*100:.2f}%\")\n",
    "print(f\"  RMSE reduction: {(rmse_bm - rmse_opt)/rmse_bm*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a4e45",
   "metadata": {},
   "source": [
    "## 6. Depth Reconstruction\n",
    "\n",
    "Convert disparity to depth using triangulation.\n",
    "\n",
    "### Depth Equation\n",
    "\n",
    "$$Z = \\frac{f \\cdot B}{d}$$\n",
    "\n",
    "where:\n",
    "- $Z$ = depth (cm)\n",
    "- $f$ = focal length (pixels)\n",
    "- $B$ = baseline (cm)\n",
    "- $d$ = disparity (pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3733528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_to_depth(disparity, focal_length, baseline):\n",
    "    \"\"\"\n",
    "    Convert disparity map to depth map.\n",
    "    \n",
    "    Parameters:\n",
    "    - disparity: Disparity map (pixels)\n",
    "    - focal_length: Camera focal length (pixels)\n",
    "    - baseline: Stereo baseline (cm)\n",
    "    \n",
    "    Returns:\n",
    "    - depth: Depth map (cm)\n",
    "    \"\"\"\n",
    "    # Avoid division by zero\n",
    "    depth = np.zeros_like(disparity)\n",
    "    valid = disparity > 0\n",
    "    depth[valid] = (focal_length * baseline) / disparity[valid]\n",
    "    \n",
    "    return depth\n",
    "\n",
    "# Convert to depth\n",
    "depth_gt = disparity_to_depth(gt_disp, cam_params['focal_length'], cam_params['baseline'])\n",
    "depth_bm = disparity_to_depth(disparity_bm, cam_params['focal_length'], cam_params['baseline'])\n",
    "depth_opt = disparity_to_depth(disparity_opt, cam_params['focal_length'], cam_params['baseline'])\n",
    "\n",
    "print(\"\u2713 Depth maps computed!\")\n",
    "print(f\"\\nDepth statistics (cm):\")\n",
    "print(f\"Ground Truth - Mean: {depth_gt[depth_gt > 0].mean():.2f}, Range: [{depth_gt[depth_gt > 0].min():.2f}, {depth_gt[depth_gt > 0].max():.2f}]\")\n",
    "print(f\"Block Matching - Mean: {depth_bm[depth_bm > 0].mean():.2f}, Range: [{depth_bm[depth_bm > 0].min():.2f}, {depth_bm[depth_bm > 0].max():.2f}]\")\n",
    "print(f\"Optimized - Mean: {depth_opt[depth_opt > 0].mean():.2f}, Range: [{depth_opt[depth_opt > 0].min():.2f}, {depth_opt[depth_opt > 0].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98372edf",
   "metadata": {},
   "source": [
    "### Visualize Depth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "im1 = axes[0].imshow(depth_gt, cmap='plasma')\n",
    "axes[0].set_title('Ground Truth Depth', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04, label='Depth (cm)')\n",
    "\n",
    "im2 = axes[1].imshow(depth_bm, cmap='plasma')\n",
    "axes[1].set_title('Block Matching Depth', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04, label='Depth (cm)')\n",
    "\n",
    "im3 = axes[2].imshow(depth_opt, cmap='plasma')\n",
    "axes[2].set_title('Optimized Depth', fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04, label='Depth (cm)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de478218",
   "metadata": {},
   "source": [
    "### Depth Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06865a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute depth errors\n",
    "valid_mask = (depth_gt > 0) & (depth_bm > 0) & (depth_opt > 0)\n",
    "\n",
    "depth_error_bm = np.abs(depth_bm - depth_gt)\n",
    "depth_error_opt = np.abs(depth_opt - depth_gt)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "im1 = axes[0].imshow(depth_error_bm, cmap='hot', vmin=0, vmax=20)\n",
    "axes[0].set_title('Block Matching Depth Error', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04, label='Absolute Error (cm)')\n",
    "\n",
    "im2 = axes[1].imshow(depth_error_opt, cmap='hot', vmin=0, vmax=20)\n",
    "axes[1].set_title('Optimized Depth Error', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04, label='Absolute Error (cm)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "mae_depth_bm = depth_error_bm[valid_mask].mean()\n",
    "mae_depth_opt = depth_error_opt[valid_mask].mean()\n",
    "rmse_depth_bm = np.sqrt((depth_error_bm[valid_mask] ** 2).mean())\n",
    "rmse_depth_opt = np.sqrt((depth_error_opt[valid_mask] ** 2).mean())\n",
    "\n",
    "print(f\"\\nDepth Error Metrics (cm):\")\n",
    "print(f\"{'Method':<30} {'MAE (cm)':<15} {'RMSE (cm)':<15}\")\n",
    "print(f\"{'-'*60}\")\n",
    "print(f\"{'Block Matching':<30} {mae_depth_bm:<15.3f} {rmse_depth_bm:<15.3f}\")\n",
    "print(f\"{'Levenberg-Marquardt':<30} {mae_depth_opt:<15.3f} {rmse_depth_opt:<15.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492b797",
   "metadata": {},
   "source": [
    "## 7. 3D Point Cloud Reconstruction\n",
    "\n",
    "Generate 3D point clouds from depth maps.\n",
    "\n",
    "### 3D Projection\n",
    "\n",
    "$$X = \\frac{(u - c_x) \\cdot Z}{f}$$\n",
    "\n",
    "$$Y = \\frac{(v - c_y) \\cdot Z}{f}$$\n",
    "\n",
    "where $(u, v)$ are pixel coordinates and $(c_x, c_y)$ is the principal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud(depth_map, image, focal_length, subsample=4):\n",
    "    \"\"\"\n",
    "    Create 3D point cloud from depth map.\n",
    "    \n",
    "    Parameters:\n",
    "    - depth_map: Depth map (cm)\n",
    "    - image: Color/intensity image\n",
    "    - focal_length: Camera focal length (pixels)\n",
    "    - subsample: Subsampling factor for efficiency\n",
    "    \n",
    "    Returns:\n",
    "    - points: 3D point coordinates (N x 3)\n",
    "    - colors: Point colors (N x 3)\n",
    "    \"\"\"\n",
    "    height, width = depth_map.shape\n",
    "    cx, cy = width / 2, height / 2\n",
    "    \n",
    "    points = []\n",
    "    colors = []\n",
    "    \n",
    "    for v in range(0, height, subsample):\n",
    "        for u in range(0, width, subsample):\n",
    "            Z = depth_map[v, u]\n",
    "            \n",
    "            if Z > 0:  # Valid depth\n",
    "                X = (u - cx) * Z / focal_length\n",
    "                Y = (v - cy) * Z / focal_length\n",
    "                \n",
    "                points.append([X, Y, Z])\n",
    "                \n",
    "                # Color (normalize grayscale to RGB)\n",
    "                intensity = image[v, u] / 255.0\n",
    "                colors.append([intensity, intensity, intensity])\n",
    "    \n",
    "    return np.array(points), np.array(colors)\n",
    "\n",
    "# Create point clouds\n",
    "print(\"Creating point clouds...\")\n",
    "points_gt, colors_gt = create_point_cloud(depth_gt, left_img, cam_params['focal_length'])\n",
    "points_bm, colors_bm = create_point_cloud(depth_bm, left_img, cam_params['focal_length'])\n",
    "points_opt, colors_opt = create_point_cloud(depth_opt, left_img, cam_params['focal_length'])\n",
    "\n",
    "print(f\"\u2713 Point clouds created!\")\n",
    "print(f\"Ground Truth: {len(points_gt)} points\")\n",
    "print(f\"Block Matching: {len(points_bm)} points\")\n",
    "print(f\"Optimized: {len(points_opt)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9321e",
   "metadata": {},
   "source": [
    "### Visualize Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Ground truth\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(points_gt[:, 0], points_gt[:, 1], points_gt[:, 2], \n",
    "           c=colors_gt, s=1, alpha=0.5)\n",
    "ax1.set_xlabel('X (cm)', fontsize=10)\n",
    "ax1.set_ylabel('Y (cm)', fontsize=10)\n",
    "ax1.set_zlabel('Z (cm)', fontsize=10)\n",
    "ax1.set_title('Ground Truth Point Cloud', fontsize=12, fontweight='bold')\n",
    "ax1.view_init(elev=20, azim=45)\n",
    "\n",
    "# Block matching\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.scatter(points_bm[:, 0], points_bm[:, 1], points_bm[:, 2], \n",
    "           c=colors_bm, s=1, alpha=0.5)\n",
    "ax2.set_xlabel('X (cm)', fontsize=10)\n",
    "ax2.set_ylabel('Y (cm)', fontsize=10)\n",
    "ax2.set_zlabel('Z (cm)', fontsize=10)\n",
    "ax2.set_title('Block Matching Point Cloud', fontsize=12, fontweight='bold')\n",
    "ax2.view_init(elev=20, azim=45)\n",
    "\n",
    "# Optimized\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.scatter(points_opt[:, 0], points_opt[:, 1], points_opt[:, 2], \n",
    "           c=colors_opt, s=1, alpha=0.5)\n",
    "ax3.set_xlabel('X (cm)', fontsize=10)\n",
    "ax3.set_ylabel('Y (cm)', fontsize=10)\n",
    "ax3.set_zlabel('Z (cm)', fontsize=10)\n",
    "ax3.set_title('Optimized Point Cloud', fontsize=12, fontweight='bold')\n",
    "ax3.view_init(elev=20, azim=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c8a76",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis\n",
    "\n",
    "Summary of computational performance and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary table\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Disparity MAE (pixels)',\n",
    "        'Disparity RMSE (pixels)',\n",
    "        'Depth MAE (cm)',\n",
    "        'Depth RMSE (cm)',\n",
    "        'Success Rate (%)'\n",
    "    ],\n",
    "    'Block Matching': [\n",
    "        f'{mae_bm:.3f}',\n",
    "        f'{rmse_bm:.3f}',\n",
    "        f'{mae_depth_bm:.3f}',\n",
    "        f'{rmse_depth_bm:.3f}',\n",
    "        '100.0'\n",
    "    ],\n",
    "    'Levenberg-Marquardt': [\n",
    "        f'{mae_opt:.3f}',\n",
    "        f'{rmse_opt:.3f}',\n",
    "        f'{mae_depth_opt:.3f}',\n",
    "        f'{rmse_depth_opt:.3f}',\n",
    "        f\"{convergence_info['successful']/convergence_info['total']*100:.1f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Metric':<30} {'Block Matching':<20} {'L-M Optimized':<20}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, metric in enumerate(summary_data['Metric']):\n",
    "    print(f\"{metric:<30} {summary_data['Block Matching'][i]:<20} {summary_data['Levenberg-Marquardt'][i]:<20}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Error comparison\n",
    "methods = ['Block\\nMatching', 'Levenberg-\\nMarquardt']\n",
    "mae_values = [mae_bm, mae_opt]\n",
    "rmse_values = [rmse_bm, rmse_opt]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, mae_values, width, label='MAE', color='steelblue', alpha=0.8)\n",
    "axes[0].bar(x + width/2, rmse_values, width, label='RMSE', color='coral', alpha=0.8)\n",
    "axes[0].set_ylabel('Error (pixels)', fontsize=12)\n",
    "axes[0].set_title('Disparity Error Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(methods)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Depth error comparison\n",
    "depth_mae_values = [mae_depth_bm, mae_depth_opt]\n",
    "depth_rmse_values = [rmse_depth_bm, rmse_depth_opt]\n",
    "\n",
    "axes[1].bar(x - width/2, depth_mae_values, width, label='MAE', color='steelblue', alpha=0.8)\n",
    "axes[1].bar(x + width/2, depth_rmse_values, width, label='RMSE', color='coral', alpha=0.8)\n",
    "axes[1].set_ylabel('Error (cm)', fontsize=12)\n",
    "axes[1].set_title('Depth Error Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(methods)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aea485",
   "metadata": {},
   "source": [
    "## 9. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Block Matching**: Provides fast, reasonable initial estimates but suffers from noise and ambiguities in textureless regions.\n",
    "\n",
    "2. **Levenberg-Marquardt Optimization**: Successfully refines disparity estimates through nonlinear least squares optimization, improving accuracy while maintaining computational efficiency.\n",
    "\n",
    "3. **Depth Reconstruction**: Accurate depth maps enable realistic 3D point cloud generation for VR applications.\n",
    "\n",
    "4. **Numerical Analysis**: The project demonstrates practical applications of numerical optimization in computer vision, showing how mathematical methods can enhance algorithmic performance.\n",
    "\n",
    "### Future Work\n",
    "\n",
    "- Implement GPU acceleration for real-time performance\n",
    "- Explore other optimization algorithms (Gauss-Newton, Trust Region)\n",
    "- Add edge-preserving smoothness constraints\n",
    "- Test on real stereo datasets (KITTI, Middlebury)\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}